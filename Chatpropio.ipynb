{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ematevez/76195-Inteligencia-Artificial/blob/main/Chatpropio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBmzoB2pPrvs",
        "outputId": "41348598-bbbb-4a1d-9596-86d85ca52495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gpt4all) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gpt4all) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2024.12.14)\n",
            "Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gpt4all\n",
            "Successfully installed gpt4all-2.8.2\n",
            "--2025-01-29 22:27:38--  https://gpt4all.io/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf\n",
            "Resolving gpt4all.io (gpt4all.io)... 172.67.71.169, 104.26.1.159, 104.26.0.159, ...\n",
            "Connecting to gpt4all.io (gpt4all.io)|172.67.71.169|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-01-29 22:27:38 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Instalar la biblioteca gpt4all\n",
        "!pip install gpt4all\n",
        "\n",
        "# Descargar un modelo compatible\n",
        "!wget https://gpt4all.io/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf -O Meta-Llama-3-8B-Instruct.Q4_0.gguf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hace falta correr este -"
      ],
      "metadata": {
        "id": "pDMzEoDQIZwZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T2EOIXMgmpYD",
        "outputId": "dfde2a2c-8e01-4f6f-ecef-4119bf9c8cfc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 4.66G/4.66G [02:09<00:00, 36.1MiB/s]\n",
            "Verifying: 100%|██████████| 4.66G/4.66G [00:18<00:00, 250MiB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatGPT listo. Escribe 'salir' para terminar.\n",
            "ChatGPT: ¡Claro! Me alegra poder recomendarte un tema. ¿Qué tipo de tema te gustaría? (por ejemplo, una película, un libro, un juego, etc.)\n",
            "\n",
            "Aquí tienes algunas sugerencias:\n",
            "\n",
            "* Si eres fanático de la ciencia ficción, podrías disfrutar del tema \"La colonización de Marte\" o \"El fin del mundo como lo conocemos\".\n",
            "* Si te gusta el misterio y el suspense, podrías elegir temas como \"Un asesinato en una isla desierta\" o \"Una investigación paranormal\".\n",
            "* Si eres un amante de la aventura, podrías disfrutar de temas como \"La búsqueda del tesoro perdido\" o \"El viaje a través del tiempo\".\n",
            "\n",
            "¿Cuál es tu área de interés?\n",
            "ChatGPT: ¡Genial! Me alegra poder recomendarte un tema musical. ¿Qué tipo de música te gusta? (por ejemplo, rock, pop, hip-hop, electronic, etc.)\n",
            "\n",
            "Aquí tienes algunas sugerencias:\n",
            "\n",
            "* Si eres fanático del rock, podrías disfrutar de temas como \"Sweet Child O' Mine\" de Guns N' Roses o \"Hotel California\" de Eagles.\n",
            "* Si te gusta el pop, podrías elegir temas como \"Happy\" de Pharrell Williams o \"Uptown Funk\" de Mark Ronson ft. Bruno Mars.\n",
            "* Si eres un amante del hip-hop, podrías disfrutar de temas como \"Lose Yourself\" de Eminem o \"God's Plan\" de Drake.\n",
            "* Si te gusta la música electrónica, podrías elegir temas como \"Sandstorm\" de Darude o \"One\" de Veracocha.\n",
            "\n",
            "¿Tienes algún artista o género en particular que te guste?\n",
            "\n",
            "(Puedo recomendarte un tema específico si me das una pista sobre lo que te gusta)\n",
            "ChatGPT: ¡Genial! Me alegra poder recomendarte un tema de música rock nacional. Hay muchos grupos y artistas excelentes en este género.\n",
            "\n",
            "Aquí tienes algunas sugerencias:\n",
            "\n",
            "* Si eres fanático del hard rock, podrías disfrutar de temas como \"La Bala\" de Maná o \"Viva la Vida\" de Caifanes.\n",
            "* Si te gusta el rock alternativo, podrías elegir temas como \"Sólo con un Beso\" de Fobia o \"El Amor y la Espada\" de Aterciopelados.\n",
            "* Si eres fanático del rock progresivo, podrías disfrutar de temas como \"La Estación\" de Serú Girán o \"Vuelta al Mundo\" de Sui Generis.\n",
            "\n",
            "Aquí tienes algunas opciones más específicas:\n",
            "\n",
            "1. **Maná**: Uno de los grupos más populares y exitosos en la historia del rock nacional mexicano.\n",
            "2. **Caifanes**: Un grupo pionero del rock alternativo en México, conocido por sus letras poéticas y melodías pegajosas.\n",
            "3. **Fobia**: Una banda argentina que combina el hard rock con elementos de punk y heavy metal.\n",
            "4. **Aterciopelados**: Un grupo colombiano que fusiona el rock con ritmos latinos y música electrónica.\n",
            "5. **Sui Generis**: Uno de los grupos más influyentes en la historia del rock progresivo argentino.\n",
            "\n",
            "¿Te gustaría algo específico? ¿Tienes algún artista o tema favorito en este género?\n",
            "\n",
            "(Puedo recomendarte un tema específico si me das una pista sobre lo que te gusta)\n",
            "ChatGPT: La pregunta del siglo!\n",
            "\n",
            "En serio, no hay un \"mejor\" lenguaje de programación. Cada lenguaje tiene sus fortalezas y debilidades, y lo que funciona bien para uno puede no funcionar tan bien para otro.\n",
            "\n",
            "Aquí te presento algunos de los lenguajes más populares y versátiles:\n",
            "\n",
            "1. **Python**: Un lenguaje fácil de aprender, con una gran cantidad de bibliotecas y frameworks para tareas como el análisis de datos, la inteligencia artificial, el desarrollo web y mucho más.\n",
            "2. **JavaScript**: Un lenguaje omnipresente en Internet, utilizado para crear aplicaciones web interactivas, juegos, animaciones y efectos especiales.\n",
            "3. **Java**: Un lenguaje robusto y escalable, ampliamente utilizado para desarrollar aplicaciones empresariales, juegos, Android apps y más.\n",
            "4. **C++**: Un lenguaje de bajo nivel con un gran control sobre la memoria y el rendimiento, ideal para desarrollo de sistemas operativos, videojuegos y aplicaciones críticas.\n",
            "5. **Swift**: Un lenguaje moderno y fácil de aprender, desarrollado por Apple para crear apps para iOS, macOS, watchOS y tvOS.\n",
            "\n",
            "Y luego hay otros lenguajes que son ideales para específicos campos o industrias:\n",
            "\n",
            "* **R** (estadística y análisis de datos)\n",
            "* **SQL** (gestión de bases de datos relacionales)\n",
            "* **Go** (desarrollo de sistemas distribuidos, networking y cloud computing)\n",
            "* **Kotlin** (desarrollo de apps para Android)\n",
            "\n",
            "En resumen, no hay un \"mejor\" lenguaje. Lo que importa es elegir el lenguaje adecuado para tu proyecto o campo específico.\n",
            "\n",
            "¿Tienes algún objetivo o área en particular donde quieres aplicar tus habilidades de programación?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f8ca5623d5b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ChatGPT listo. Escribe 'salir' para terminar.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpregunta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tú: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpregunta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"salir\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"¡Adiós!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "from gpt4all import GPT4All\n",
        "\n",
        "# Cargar el modelo descargado\n",
        "model_path = \"Meta-Llama-3-8B-Instruct.Q4_0.gguf\"  # Ruta del modelo descargado\n",
        "model = GPT4All(model_path)  # Inicializa el modelo\n",
        "\n",
        "# Crear sesión de chat\n",
        "with model.chat_session() as session:\n",
        "    print(\"ChatGPT listo. Escribe 'salir' para terminar.\")\n",
        "    while True:\n",
        "        pregunta = input(\"Tú: \")\n",
        "        if pregunta.lower() == \"salir\":\n",
        "            print(\"¡Adiós!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            respuesta = session.generate(pregunta, max_tokens=1024)\n",
        "            print(f\"ChatGPT: {respuesta}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al generar respuesta: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DESAFIO 1 de CLASE:\n",
        "\n",
        "Eres un experto en programación y necesitas generar un script en Python que utiliza el modelo GPT4All para crear tareas pendientes basadas en una descripción de un evento proporcionada por el usuario.\n",
        "\n",
        "El script debe:\n",
        "\n",
        "Importar el módulo GPT4All.\n",
        "Cargar el modelo Meta-Llama-3-8B-Instruct.Q4_0.gguf.\n",
        "Contener una función llamada generar_tareas(prompt) que:\n",
        "Reciba un texto (prompt) como parámetro.\n",
        "Use una sesión de chat del modelo GPT4All para generar una respuesta.\n",
        "Tenga un límite de 512 tokens en la respuesta.\n",
        "Solicitar al usuario que introduzca una descripción de un evento mediante input.\n",
        "Crear un prompt que use esta descripción para generar una lista de tareas pendientes.\n",
        "Mostrar las tareas generadas automáticamente.\n",
        "Genera el código completo para este propósito. Explicame paso a paso que hiciste y que tengo que instalar para que sea funcional en colab\n",
        "ChatGPT Plus\n",
        "ChatGPT\n",
        "Aquí tienes el código completo para el script en Python que utiliza el modelo GPT4All para generar tareas pendientes basadas en la descripción de un evento proporcionada por el usuario. Después del código, te explico paso a paso su funcionamiento y lo que necesitas instalar en Google Colab."
      ],
      "metadata": {
        "id": "naS5OwomHWgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from gpt4all import GPT4All\n",
        "\n",
        "def generar_tareas(prompt):\n",
        "    # Cargar el modelo GPT4All\n",
        "    model_name = \"Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n",
        "    model = GPT4All(model_name)\n",
        "\n",
        "    # Generar respuesta con un límite de 512 tokens\n",
        "    with model.chat_session() as chat:\n",
        "        response = chat.generate(prompt, max_tokens=512)\n",
        "\n",
        "    return response\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Solicitar la descripción del evento al usuario\n",
        "    descripcion_evento = input(\"Por favor, describe el lugar donde irias : \")\n",
        "\n",
        "    # Crear el prompt\n",
        "    prompt = f\"Dado el siguiente lugar: '{descripcion_evento}', genera una lista de tareas y cosas necesarias para efectuar paseaos y caminatas.\"\n",
        "\n",
        "    # Generar las tareas\n",
        "    tareas = generar_tareas(prompt)\n",
        "\n",
        "    # Mostrar las tareas generadas\n",
        "    print(\"\\nTareas generadas:\")\n",
        "    print(tareas)\n"
      ],
      "metadata": {
        "id": "g-7GlbXiHUIn",
        "outputId": "bcc43e5c-8584-429b-be44-b51b8e44566d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Por favor, describe el lugar donde irias : playa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 4.66G/4.66G [01:56<00:00, 39.9MiB/s]\n",
            "Verifying: 100%|██████████| 4.66G/4.66G [00:18<00:00, 246MiB/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}